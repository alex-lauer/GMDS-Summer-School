[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Longitudinal Data Modeling",
    "section": "",
    "text": "Preface"
  },
  {
    "objectID": "intro.html#workshop-structure",
    "href": "intro.html#workshop-structure",
    "title": "1  Introduction",
    "section": "1.1 Workshop Structure",
    "text": "1.1 Workshop Structure\nThis class focuses on the longitudinal modeling of data from Patient Reported Outcomes (PROs). It is meant to be hands-on class with applications in R.\nContent and structure follow the book by (Mallinckrodt 2016). We would like to extend our warmest gratitude towards Dr. Mallinckrodt for providing the example data for the workshop.\nThe following topics will be covered:\n\nWelcome and Introduction (WS session 1)\nExploration and visualization of longitudinal data (WS session 1/2)\nInferences from longitudinal data (WS session 3 + 4)\nAssessment of missingness patterns (WS session 5)\nSensitivity analyses to assess the impact of missingness (WS session 6)\nAnnex: Inferences from longitudinal binary data (WS session 7)"
  },
  {
    "objectID": "intro.html#longitudinal-data",
    "href": "intro.html#longitudinal-data",
    "title": "1  Introduction",
    "section": "1.2 Longitudinal Data",
    "text": "1.2 Longitudinal Data\nThis workshop focuses on the analysis of data observed in randomized clinical trials (RCTs). Here, patients have assessments taken at the start of their treatment and then subsequently throughout the course of the trial based on a pre-specified schedule of assessments. The measurement at the start of the treatment is usually referred to as the baseline.\nResearchers can be interested in\n\nthe occurrence of a certain event during the course of the trial, e.g. death or a cardiac event, or the time to the occurrence of such an event, or\nthe longitudinal profile from multiple repeated measurements taken, with a focus on either estimates at a landmark visit or across several time points.\n\nThe outcomes under point 1. can be handled via a comparison of the percentages of patients with events between treatment arms, or a time-to-event analysis. Both are out of scope of this workshop."
  },
  {
    "objectID": "intro.html#basics-about-rstudio-pre-read",
    "href": "intro.html#basics-about-rstudio-pre-read",
    "title": "1  Introduction",
    "section": "1.3 Basics about RStudio (pre-read)",
    "text": "1.3 Basics about RStudio (pre-read)\nAlex to add pre-read (YouTube + Cheat Sheets)"
  },
  {
    "objectID": "intro.html#example-data",
    "href": "intro.html#example-data",
    "title": "1  Introduction",
    "section": "1.4 Example data",
    "text": "1.4 Example data\n\n\n\n\nMallinckrodt, Craig. 2016. Analyzing Longitudinal Clinical Trial Data. Chapman; Hall/CRC. https://doi.org/10.1201/9781315186634."
  },
  {
    "objectID": "s1_visualization.html",
    "href": "s1_visualization.html",
    "title": "2  Longitudinal Data Exploration and Visualization",
    "section": "",
    "text": "3 Correlation structure, covariance matrices"
  },
  {
    "objectID": "s1_visualization.html#introduction",
    "href": "s1_visualization.html#introduction",
    "title": "2  Longitudinal Data Exploration and Visualization",
    "section": "2.1 Introduction",
    "text": "2.1 Introduction\n\nData on individuals followed over time with information collected at several time points.\nClusters are the individuals who are followed over time.\nRepeated observations may or may not be taken at regular times (balanced, fixed occasions, do not differ between subjects).\nOur interest is in the change from baseline.\n\nDatasets used in this course: Example data is taken from (Mallinckrodt 2016). Contain data on the HAMD17 (Hamilton 17-item rating scale for depression). Two treatement arms are included: drug vs. placebo. Assessments were taken at baseline and weeks 1, 2, 4, 6, and 8\nThere are 3 data sets created from the original data: - all2 Subsample of the large dataset with n=50, visits: weeks 2, 4, 8 - high2 Large dataset with n=100, high dropout = 70% (drug), 60% (placebo) - low2 Large dataset with n=100, low dropout = 18%"
  },
  {
    "objectID": "s1_visualization.html#task-1---exploration-of-dataset-all2---15-minutes-working-time",
    "href": "s1_visualization.html#task-1---exploration-of-dataset-all2---15-minutes-working-time",
    "title": "2  Longitudinal Data Exploration and Visualization",
    "section": "2.2 Task 1 - Exploration of dataset all2 - 15 Minutes working time",
    "text": "2.2 Task 1 - Exploration of dataset all2 - 15 Minutes working time\n\nAre the data balanced and equally spaced?\nNumber of observations by week?\nSummary statistics for HAMD17 (change from baseline) by week.\nPlot trajectories for each individual, different colors for each treatment group (or panels). Add mean to your plot. ODER Mean plot separat evtl. mit CI\nGenerate and interpret the group-wise boxplots of the change from baseline.\nPlot trajectories separately by gender. Comment on the plots.\n\n\n2.2.1 Task 1 Discussion, possible solution\nTO DO: Datensatz aufbereiten, Label, Time=Faktor (t) Alex: library gtsummary okay? Oder sollen wir es anders machen\nTable: Summary statistics for HAMD17 by treatment and week in the all2 dataset\n\nall2 %&gt;%\n  select(change, group, avisit) %&gt;%\n  tbl_strata(strata=group, \n             ~.x %&gt;% \n               tbl_summary(by = avisit,\n                           statistic = list(\n      all_continuous() ~ \"{mean} ({sd})\"), \n      digits = all_continuous() ~ 2 ) \n)\n\n\n\n\n\n  \n    \n    \n      Characteristic\n      \n        Arm 1\n      \n      \n        Arm 2\n      \n    \n    \n      Week 2, N = 251\n      Week 4, N = 251\n      Week 8, N = 251\n      Week 2, N = 251\n      Week 4, N = 251\n      Week 8, N = 251\n    \n  \n  \n    change\n-4.20 (3.66)\n-6.80 (4.25)\n-9.88 (4.85)\n-5.24 (5.49)\n-8.60 (5.39)\n-13.24 (5.54)\n  \n  \n  \n    \n      1 Mean (SD)\n    \n  \n\n\n\n\nFigure: trajectories\n\nggplot(data = all2, aes(x = avisit, y = change, group=subject)) +\ngeom_point() + geom_line() + facet_grid(.~group)\n\n\n\n\nFigure 2.1: Individual trajectories of HAMD17 by treatment group\n\n\n\n\n\nggplot(data = all2, aes(x = avisit, y = change)) + \n  geom_point() + facet_grid(.~group) +\n  stat_summary(aes(group = 1), geom = \"line\", fun.y = mean,\n               size = 1, col=\"blue\") +\n  stat_summary(aes(group = 1), geom = \"point\", fun.y = mean,\n               shape=17,size = 3, col=\"blue\")\n\nWarning: The `fun.y` argument of `stat_summary()` is deprecated as of ggplot2 3.3.0.\nℹ Please use the `fun` argument instead.\n\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\nFigure 2.2: Mean change from baseline by treatment group"
  },
  {
    "objectID": "s1_visualization.html#overview---different-covariance-matrices",
    "href": "s1_visualization.html#overview---different-covariance-matrices",
    "title": "2  Longitudinal Data Exploration and Visualization",
    "section": "3.1 Overview - different covariance matrices",
    "text": "3.1 Overview - different covariance matrices\n\nVariance components (VC) independence structure\nCompound symmetry (CS) also known as exchangeable\nToeplitz (TOEP)\nFirst order auto regressive (AR(1))\nUnstructured (UN)\n\nSelected covariance structures for data with three assessment times are shown below. Note that with three assessment times, the number of parameters estimated for the various structures did not differ as much as would be the case with more assessment times. Thus, results from different covariance structures are more similar than would be the case with more assessment times.\n\n3.1.1 Independence structure (VC)\nConstant variance. It is assumed to be no correlation between assessments. \\[ \\begin{bmatrix}\n   \\sigma^2   & 0  & 0  \\\\\n   0  & \\sigma^2   & 0 \\\\\n   0  & 0  & \\sigma^2\n   \\end{bmatrix}\\]\n\n\n3.1.2 Compound symmetry (CS)\nConstant variance and constant covariance across all assessments. Also known as exchangeable.\n\\[ \\begin{bmatrix}\n   \\sigma^2 + \\sigma_1 & \\sigma_1  & \\sigma_1  \\\\\n   \\sigma_1  & \\sigma^2 + \\sigma_1  & \\sigma_1  \\\\\n   \\sigma_1  & \\sigma_1  & \\sigma^2 + \\sigma_1\n   \\end{bmatrix}\\]\n\n\n3.1.3 Unstructured (UN)\nThis is the most general (saturated) model\n\\[ \\begin{bmatrix}\n   \\sigma_1^2 & \\sigma_{21}  & \\sigma_{31}  \\\\\n   \\sigma_{21}  & \\sigma_2^2   & \\sigma_{32}  \\\\\n   \\sigma_{31}  & \\sigma_{32}  & \\sigma_3^2\n   \\end{bmatrix}\\]\n\n\n3.1.4 Toeplitz structure (TOEP)\nHomogenous variances and heterogenous correlations. Same correlation value is used whenever the degree of adjacency is the same e.g. correlation between times 1 and 2 = correlation between times 2 and 3.\n\\[ \\begin{bmatrix}\n   \\sigma^2  & \\sigma^2 \\rho_1  & \\sigma^2 \\rho_2  \\\\\n   \\sigma^2 \\rho_1 & \\sigma^2   & \\sigma^2 \\rho_1  \\\\\n   \\sigma^2 \\rho_2  & \\sigma^2 \\rho_1  & \\sigma^2\n   \\end{bmatrix}\\]\n\n\n3.1.5 Autoregressive structure (AR(1))\nCorrelation decreases as time between observations increases.\n\\[ \\begin{bmatrix}\n   \\sigma^2  & \\sigma^2 \\rho  & \\sigma^2 \\rho^2  \\\\\n   \\sigma^2 \\rho & \\sigma^2   & \\sigma^2 \\rho  \\\\\n  \\sigma^2 \\rho^2  & \\sigma^2 \\rho  & \\sigma^2\n   \\end{bmatrix}\\]\n\n\n3.1.6 Spatial (SP)\nSpatial covariance structures does not require that the timepoints are consistent between subjects. Instead, as long as the distance between visits can be quantified in terms of time and/or other coordinates, the spatial covariance structure can be applied.\nFor spatial exponential, the covariance structure is defined as follows: \\[ \\rho_{ij}=\\rho^{d_{ij}} \\] where \\[d_{ij} \\] is the distance between time point i and time point j."
  },
  {
    "objectID": "s1_visualization.html#selecting-the-covariance-structure",
    "href": "s1_visualization.html#selecting-the-covariance-structure",
    "title": "2  Longitudinal Data Exploration and Visualization",
    "section": "3.2 Selecting the covariance structure",
    "text": "3.2 Selecting the covariance structure\nThere are a variety of considerations when selecting the covariance structure: - number of parameters - interpretation of the structure - model fit UN is the most flexible. Choose a reasonable covaraiance structure which is the best compromise between model fit and complexity. E.g. use AIC as it penalises more complex models."
  },
  {
    "objectID": "s1_visualization.html#task---exploration-of-correlation-in-the-data",
    "href": "s1_visualization.html#task---exploration-of-correlation-in-the-data",
    "title": "2  Longitudinal Data Exploration and Visualization",
    "section": "3.3 Task - Exploration of correlation in the data",
    "text": "3.3 Task - Exploration of correlation in the data\n\nCompute the empirical correlations between measurement timepoints (e.g. correlation between baseline and post-baseline changes).\nLooking at these correlations, comment on the suitability of the correlation structures VC, CS, UN, AR(1).\n\n\n1 + 1\n\n[1] 2\n\n\n\n\n\n\nMallinckrodt, Craig. 2016. Analyzing Longitudinal Clinical Trial Data. Chapman; Hall/CRC. https://doi.org/10.1201/9781315186634."
  },
  {
    "objectID": "s2_inference_continuous.html#categorical-time",
    "href": "s2_inference_continuous.html#categorical-time",
    "title": "3  Inference from Longitudinal Data",
    "section": "3.1 Categorical Time",
    "text": "3.1 Categorical Time\navisit with three distinct values -&gt; 2 df\n\n?mmrm\n\n\nfit_cat_time &lt;- mmrm::mmrm(\n  formula = change ~ basval*avisit + trt*avisit + us(avisit | subject),\n  data = all2,\n  control = mmrm_control(method = \"Kenward-Roger\")\n)\n\nsummary(fit_cat_time)\n\nmmrm fit\n\nFormula:     change ~ basval * avisit + trt * avisit + us(avisit | subject)\nData:        all2 (used 150 observations from 50 subjects with maximum 3 \ntimepoints)\nCovariance:  unstructured (6 variance parameters)\nMethod:      Kenward-Roger\nVcov Method: Kenward-Roger\nInference:   REML\n\nModel selection criteria:\n     AIC      BIC   logLik deviance \n   822.4    833.9   -405.2    810.4 \n\nCoefficients: \n                     Estimate Std. Error        df t value Pr(&gt;|t|)   \n(Intercept)           1.98452    3.27479  47.00000   0.606  0.54743   \nbasval               -0.31235    0.15905  47.00000  -1.964  0.05548 . \navisitWeek 4         -0.90862    2.39866  47.00000  -0.379  0.70654   \navisitWeek 8        -10.58630    3.45922  47.00000  -3.060  0.00365 **\ntrt2                 -1.18993    1.27265  47.00000  -0.935  0.35457   \nbasval:avisitWeek 4  -0.08542    0.11650  47.00000  -0.733  0.46704   \nbasval:avisitWeek 8   0.24779    0.16801  47.00000   1.475  0.14691   \navisitWeek 4:trt2    -0.80100    0.93217  47.00000  -0.859  0.39454   \navisitWeek 8:trt2    -2.20106    1.34432  47.00000  -1.637  0.10825   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCovariance estimate:\n        Week 2  Week 4  Week 8\nWeek 2 20.6112 15.3034 12.2766\nWeek 4 15.3034 21.3565 17.6648\nWeek 8 12.2766 17.6648 27.6127\n\n\nCan extract covariance matrix via\n\nsummary(fit_cat_time)$varcor\n\n         Week 2   Week 4   Week 8\nWeek 2 20.61117 15.30339 12.27661\nWeek 4 15.30339 21.35648 17.66478\nWeek 8 12.27661 17.66478 27.61271"
  },
  {
    "objectID": "s2_inference_continuous.html#continuous-time",
    "href": "s2_inference_continuous.html#continuous-time",
    "title": "3  Inference from Longitudinal Data",
    "section": "3.2 Continuous Time",
    "text": "3.2 Continuous Time\nTime as continuous effect -&gt; single df for time and trt-by-time interaction\nModeling: - Need avisit for structure of covariance matrix - Implicit assumption is for the covariance between values for two timepoints to be equal, regardless of the specific timing\n\nfit_cont_time &lt;- mmrm::mmrm(\n  formula = change ~ basval*time + trt*time + us(avisit | subject),\n  weights = all2$time,\n  data = all2,\n  control = mmrm_control(method = \"Kenward-Roger\")\n)\n\nQuadratic trend\n\nall2$timesq &lt;- all2$time^2\n\nfit_cont_timesq &lt;- mmrm::mmrm(\n  formula = change ~ basval*timesq + trt*timesq + us(avisit | subject),\n  weights = all2$time,\n  data = all2,\n  control = mmrm_control(method = \"Kenward-Roger\")\n)\n\nmodel checks - residuals per time point"
  },
  {
    "objectID": "s2_inference_continuous.html#baseline-as-a-response-clda-lda",
    "href": "s2_inference_continuous.html#baseline-as-a-response-clda-lda",
    "title": "3  Inference from Longitudinal Data",
    "section": "3.3 Baseline as a Response (cLDA + LDA)",
    "text": "3.3 Baseline as a Response (cLDA + LDA)\n\n3.3.1 Adjustment of LS Means Calculations\nobserved vs. balanced margins -&gt; interpretation comparison to arithmetic (observed means)\n\n\n3.3.2 Addendum on RS&I Models\nDifferent dosing/ assessment frequency between treatment arms in parallel design -&gt; oncology (chemo with fixed cycles vs immune-therapy)"
  },
  {
    "objectID": "s4_sensitivity_analyses.html#simple-approaches",
    "href": "s4_sensitivity_analyses.html#simple-approaches",
    "title": "5  Sensitivity Analyses",
    "section": "5.1 Simple approaches",
    "text": "5.1 Simple approaches\nIn general, not recommended for use. Methods are of histroic interest and provide a useful starting point - LOCF: used in the past, justified as it was thought that it provides conservative estimates - complete case (observed case/completers analysis): creates selection bias, may cause overestimation of within group effects particularly at the last scheduled visit"
  },
  {
    "objectID": "s4_sensitivity_analyses.html#missing-covariates-baseline-data",
    "href": "s4_sensitivity_analyses.html#missing-covariates-baseline-data",
    "title": "5  Sensitivity Analyses",
    "section": "5.2 Missing covariates (baseline data)",
    "text": "5.2 Missing covariates (baseline data)\n\nmissing baseline value of the outcome: MI or use of mean imputation (Paper: ),\nMMRM not efficient or potential biased estimates as subjects with missing covariates are excluded from the analysis"
  },
  {
    "objectID": "s4_sensitivity_analyses.html#baseline-complete-missingness-in-post-baseline-values",
    "href": "s4_sensitivity_analyses.html#baseline-complete-missingness-in-post-baseline-values",
    "title": "5  Sensitivity Analyses",
    "section": "5.3 Baseline complete, missingness in post-baseline values",
    "text": "5.3 Baseline complete, missingness in post-baseline values\n\nfor MMRM: at least one post-baseline value needed\nAlternative: LDA where baseline is part of the response vector\nwhen implemented in similar manners: MI and MMRM have similar assumptions and yield similar results. Thus, MI implemented similarly to MMRM is not a sensitivity analysis"
  },
  {
    "objectID": "s4_sensitivity_analyses.html#multiple-imputation",
    "href": "s4_sensitivity_analyses.html#multiple-imputation",
    "title": "5  Sensitivity Analyses",
    "section": "5.4 Multiple imputation",
    "text": "5.4 Multiple imputation\n\nMI very useful for sensitivity analyses"
  },
  {
    "objectID": "s4_sensitivity_analyses.html#handling-nonignorable-missingness-mnar",
    "href": "s4_sensitivity_analyses.html#handling-nonignorable-missingness-mnar",
    "title": "5  Sensitivity Analyses",
    "section": "5.5 Handling nonignorable missingness (MNAR)",
    "text": "5.5 Handling nonignorable missingness (MNAR)\n\nAssumption of MAR is often reasonable, but possibility of data missing not at random (MNAR) is difficult to rule out.\nThus, analysis under MNAR needed\nAnalysis under MNAR: these methods are heavily assumption driven and the assumptions are not testable as we do not have the missing data\nConsider a sensitivity analsyis framework allowing assessment of robustness of results to the various assumptions\nMNAR methods: Pattern-mixture, delta-adjustment method (controlled imputation; another method is reference-based imputation)"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Craig Mallinckrodt, Ilya Lipkovich. 2016. Analyzing Longitudinal\nClinical Trial Data: A Practical Guide. Vol. 1. USA: Chapman;\nHall/CRC. https://doi.org/10.1201/9781315186634.\n\n\nLittle, Roderick, and Donald Rubin. 2019. “Statistical Analysis\nwith Missing Data, Third Edition.” Wiley Series in\nProbability and Statistics, April. https://doi.org/10.1002/9781119482260.\n\n\nMallinckrodt, Craig. 2016. Analyzing Longitudinal Clinical Trial\nData. Chapman; Hall/CRC. https://doi.org/10.1201/9781315186634.\n\n\n(Little and Rubin 2019)\n(Craig Mallinckrodt 2016)"
  }
]